{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PFfIamvkp36"
      },
      "source": [
        "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-lxPRghkp36"
      },
      "outputs": [],
      "source": [
        "file_path = \"farmers-protest-tweets-2021-2-4.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entendiendo generalmente los problemas\n",
        "\n",
        "El challenge indica que debo presentar dos soluciones, una enfocada en memoria y otra en tiempo de ejecucion. Es decir:\n",
        "\n",
        "Lo que necesito para la soluci√≥n enfocada en el tiempo de ejecuci√≥n es\n",
        "reducir o minimizar el tiempo total que tarde la funcion\n",
        "\n",
        "\n",
        "Lo que necesito para la soluci√≥n enfocada en el tiempo de ejecuci√≥n es\n",
        "reducir o minimizar la cantidad de ram que utilice la funcion durante la ejecucion.\n"
      ],
      "metadata": {
        "id": "1gEAfD4B4St6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uaSmmbY06jrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Revisando la estrucutura de los datos"
      ],
      "metadata": {
        "id": "JV6QSk7s6kR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def read_file(file_path):\n",
        "    processed_data = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            try:\n",
        "                json_object = json.loads(line.strip())\n",
        "                processed_data.append(json_object)\n",
        "                break\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON: {e}\")\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "output_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "json_data = read_file(file_path)\n",
        "print(json_data[0].keys())\n"
      ],
      "metadata": {
        "id": "Iu_t1Vljkqtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d9a7f8-becb-403a-96c4-11c4c820637c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['url', 'date', 'content', 'renderedContent', 'id', 'user', 'outlinks', 'tcooutlinks', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount', 'conversationId', 'lang', 'source', 'sourceUrl', 'sourceLabel', 'media', 'retweetedTweet', 'quotedTweet', 'mentionedUsers'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "voy identificar los campos que estare utilizando a lo largo de los 3 problemas\n",
        "\n"
      ],
      "metadata": {
        "id": "MwKksTKu7GgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# q1\n",
        "print('date', json_data[0]['date'])\n",
        "print('user', json_data[0]['user'])\n",
        "print('username', json_data[0]['user']['username'])\n",
        "\n",
        "# q2 y q3\n",
        "print('content', json_data[0]['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k45C0aF69vO",
        "outputId": "5a7ec968-6725-49c7-f826-c7657518adab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 2021-02-24T09:23:35+00:00\n",
            "user {'username': 'ArjunSinghPanam', 'displayname': 'Arjun Singh Panam', 'id': 45091142, 'description': 'Global Citizen, Actor, Director: Sky is the roof above my head, the world is the road I travel, love is my food & mother earth is my bed. Roy in @CosmosMovie', 'rawDescription': 'Global Citizen, Actor, Director: Sky is the roof above my head, the world is the road I travel, love is my food & mother earth is my bed. Roy in @CosmosMovie', 'descriptionUrls': [], 'verified': False, 'created': '2009-06-06T07:50:57+00:00', 'followersCount': 603, 'friendsCount': 311, 'statusesCount': 17534, 'favouritesCount': 4269, 'listedCount': 23, 'mediaCount': 1211, 'location': '', 'protected': False, 'linkUrl': 'https://www.cosmosmovieofficial.com', 'linkTcourl': 'https://t.co/3uaoV3gCt3', 'profileImageUrl': 'https://pbs.twimg.com/profile_images/1215541746492461056/3De61YoQ_normal.jpg', 'profileBannerUrl': 'https://pbs.twimg.com/profile_banners/45091142/1612601766', 'url': 'https://twitter.com/ArjunSinghPanam'}\n",
            "username ArjunSinghPanam\n",
            "content The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \n",
            "\n",
            "@narendramodi @DelhiPolice Shame on you. \n",
            "\n",
            "#ModiDontSellFarmers \n",
            "#FarmersProtest \n",
            "#FreeNodeepKaur https://t.co/es3kn0IQAF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### En esta seccion se resolveran los problemas"
      ],
      "metadata": {
        "id": "Wnglx1Ul-1K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primer acercamiento general para resolver ambos problemas"
      ],
      "metadata": {
        "id": "D6Ip_6tJAOd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Acercamiento para resolver optimizando el tiempo de ejecucion**\n",
        "\n",
        "Para reducir el tiempo de ejecucion podriamos cargar el dataset completo a memoria para que podamos acceder a la data con mayor rapidez.\n",
        "Posteriormente podemos cargar esa informacion a un dataframe de pandas ya que las operaciones  se enceuntran optimizadas.\n",
        "\n",
        "**Acercamiento para resolver optimizando el uso de ram**\n",
        "\n",
        "Leer en streaming o linea por linea para evitar cargar en memoria todo el dataset, podemos lograr esto de alguna forma con iteradores o generadores de python asi solo tendresmos la informacion necesaria en memoria.\n"
      ],
      "metadata": {
        "id": "wSDvL44mAjj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pregunta 1"
      ],
      "metadata": {
        "id": "KfbuPqucAggn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as. Debe incluir las siguientes funciones:\n",
        "```python\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "```\n",
        "```python\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(datetime.date(1999, 11, 15), \"LATAM321\"), (datetime.date(1999, 7, 15), \"LATAM_CHI\"), ...]\n",
        "```"
      ],
      "metadata": {
        "id": "oSg7Df6M_pHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
        "\n",
        "    df['username'] = df['user'].apply(lambda x: x['username'])\n",
        "\n",
        "    top_dates = df['date'].value_counts().nlargest(10).index.tolist()\n",
        "\n",
        "    result = []\n",
        "    for date in top_dates:\n",
        "        df_date = df[df['date'] == date]\n",
        "        top_user = df_date['username'].value_counts().idxmax()\n",
        "        result.append((date, top_user))\n",
        "\n",
        "    return result\n",
        "\n",
        "q1_time(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoUiVIYP7DKg",
        "outputId": "39dd81db-cc70-44f3-a7d9-193b8b660c6a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
              " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
              " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
              " (datetime.date(2021, 2, 16), 'jot__b'),\n",
              " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
              " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
              " (datetime.date(2021, 2, 15), 'jot__b'),\n",
              " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
              " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
              " (datetime.date(2021, 2, 19), 'Preetm91')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Midiendo el tiempo de ejecucion:"
      ],
      "metadata": {
        "id": "CfFYj8ExCy56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "import pstats\n",
        "import io\n",
        "\n",
        "pr = cProfile.Profile()\n",
        "\n",
        "pr.enable()\n",
        "result = q1_time(file_path)\n",
        "pr.disable()\n",
        "\n",
        "s = io.StringIO()\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats('cumulative' )\n",
        "ps.print_stats(5)\n",
        "print(s.getvalue())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTFo1yyt_sSK",
        "outputId": "67eda9d5-394e-4afd-845f-fbe9dabb7252"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         616539 function calls (615855 primitive calls) in 17.319 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "   List reduced from 697 to 5 due to restriction <5>\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        2    0.000    0.000   17.318    8.659 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3512(run_code)\n",
            "        2    0.000    0.000   17.318    8.659 {built-in method builtins.exec}\n",
            "        1    0.721    0.721   17.318   17.318 <ipython-input-24-ca349d025676>:1(<cell line: 8>)\n",
            "        1    0.076    0.076   16.597   16.597 <ipython-input-19-b6158fe0ac40>:5(q1_time)\n",
            "        1    0.022    0.022   16.126   16.126 /usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py:505(read_json)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la medir la memoria con memory-profiler necesito ejecutar el archivo de python desde la linea de comandos el codigo sera el mismo de arriba, unicamente agregare el decorador @profile.\n",
        "\n",
        "Para ello creare otro archivo para asi no afectar a los ya existentes en el proyecto"
      ],
      "metadata": {
        "id": "AIbeXqrQDIWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler\n",
        "!python /content/q1_time_mp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBuHE4LvCwnr",
        "outputId": "5c6317d4-692b-4864-b7de-218b4edfc5a4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Filename: /content/q1_time_mp.py\n",
            "\n",
            "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
            "=============================================================\n",
            "     6    116.6 MiB    116.6 MiB           1   @profile\n",
            "     7                                         def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
            "     8                                             # Read the NDJSON file into a pandas DataFrame\n",
            "     9   1997.6 MiB   1881.0 MiB           1       df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
            "    10                                             \n",
            "    11   2001.0 MiB      3.4 MiB           1       df['date'] = pd.to_datetime(df['date']).dt.date\n",
            "    12                                             \n",
            "    13   2001.0 MiB      0.0 MiB      234815       df['username'] = df['user'].apply(lambda x: x['username'])\n",
            "    14                                             \n",
            "    15   2001.6 MiB      0.5 MiB           1       top_dates = df['date'].value_counts().nlargest(10).index.tolist()\n",
            "    16                                             \n",
            "    17   2001.6 MiB      0.0 MiB           1       result = []\n",
            "    18   2001.6 MiB      0.0 MiB          11       for date in top_dates:\n",
            "    19   2001.6 MiB      0.0 MiB          10           df_date = df[df['date'] == date]\n",
            "    20   2001.6 MiB      0.0 MiB          10           top_user = df_date['username'].value_counts().idxmax()\n",
            "    21   2001.6 MiB      0.0 MiB          10           result.append((date, top_user))\n",
            "    22                                             \n",
            "    23   2001.6 MiB      0.0 MiB           1       return result\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    date_counts = defaultdict(int)\n",
        "    user_counts_per_date = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            tweet = json.loads(line)\n",
        "            date_str = tweet['date'][:10]\n",
        "            date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
        "            username = tweet['user']['username']\n",
        "\n",
        "            date_counts[date] += 1\n",
        "            user_counts_per_date[date][username] += 1\n",
        "\n",
        "    top_dates = sorted(date_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    result = []\n",
        "    for date, _ in top_dates:\n",
        "        user_counts = user_counts_per_date[date]\n",
        "        top_user = max(user_counts.items(), key=lambda x: x[1])[0]\n",
        "        result.append((date, top_user))\n",
        "\n",
        "    return result\n",
        "\n",
        "q1_memory(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb0ijKAKJ9A1",
        "outputId": "c07a8d91-fe71-438d-91f0-0f714ee42345"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
              " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
              " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
              " (datetime.date(2021, 2, 16), 'jot__b'),\n",
              " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
              " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
              " (datetime.date(2021, 2, 15), 'jot__b'),\n",
              " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
              " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
              " (datetime.date(2021, 2, 19), 'Preetm91')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "import pstats\n",
        "import io\n",
        "\n",
        "pr = cProfile.Profile()\n",
        "\n",
        "pr.enable()\n",
        "result = q1_memory(file_path)\n",
        "pr.disable()\n",
        "\n",
        "s = io.StringIO()\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats('cumulative' )\n",
        "ps.print_stats(5)\n",
        "print(s.getvalue())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9K0YGKnJ8-N",
        "outputId": "e5d1a642-1855-4d81-882f-d022d4c111d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         4253073 function calls in 14.764 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "   List reduced from 65 to 5 due to restriction <5>\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        2    0.000    0.000   14.764    7.382 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3512(run_code)\n",
            "        2    0.000    0.000   14.764    7.382 {built-in method builtins.exec}\n",
            "        1    0.001    0.001   14.764   14.764 <ipython-input-26-4354b2f277ac>:1(<cell line: 8>)\n",
            "        1    2.806    2.806   14.763   14.763 <ipython-input-22-230961d9bc42>:4(q1_memory)\n",
            "   117407    0.285    0.000    7.372    0.000 /usr/lib/python3.10/json/__init__.py:299(loads)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler\n",
        "!python /content/q1_memory_mp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlsBpTpVJ83a",
        "outputId": "a993818a-4f46-4c14-97fc-0ea54435fd6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Filename: /content/q1_memory_mp.py\n",
            "\n",
            "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
            "=============================================================\n",
            "     5     37.8 MiB     37.8 MiB           1   @profile\n",
            "     6                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
            "     7     37.8 MiB      0.0 MiB           1       import json\n",
            "     8     37.8 MiB      0.0 MiB           1       from collections import defaultdict\n",
            "     9     37.8 MiB      0.0 MiB           1       import datetime\n",
            "    10                                         \n",
            "    11     37.8 MiB      0.0 MiB           1       date_counts = defaultdict(int)\n",
            "    12     42.7 MiB      0.0 MiB          27       user_counts_per_date = defaultdict(lambda: defaultdict(int))\n",
            "    13                                         \n",
            "    14     43.5 MiB      0.0 MiB           2       with open(file_path, 'r', encoding='utf-8') as f:\n",
            "    15     43.5 MiB      0.6 MiB      117408           for line in f:\n",
            "    16     43.5 MiB      3.1 MiB      117407               tweet = json.loads(line)\n",
            "    17     43.5 MiB      0.0 MiB      117407               date_str = tweet['date'][:10]\n",
            "    18     43.5 MiB      0.0 MiB      117407               date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()\n",
            "    19     43.5 MiB      0.0 MiB      117407               username = tweet['user']['username']\n",
            "    20                                         \n",
            "    21     43.5 MiB      0.0 MiB      117407               date_counts[date] += 1\n",
            "    22     43.5 MiB      2.1 MiB      117407               user_counts_per_date[date][username] += 1\n",
            "    23                                         \n",
            "    24     43.5 MiB      0.0 MiB          27       top_dates = sorted(date_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
            "    25                                         \n",
            "    26     43.5 MiB      0.0 MiB           1       result = []\n",
            "    27     43.5 MiB      0.0 MiB          11       for date, _ in top_dates:\n",
            "    28     43.5 MiB      0.0 MiB          10           user_counts = user_counts_per_date[date]\n",
            "    29     43.5 MiB      0.0 MiB       88328           top_user = max(user_counts.items(), key=lambda x: x[1])[0]\n",
            "    30     43.5 MiB      0.0 MiB          10           result.append((date, top_user))\n",
            "    31                                         \n",
            "    32     43.5 MiB      0.0 MiB           1       return result\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Observaciones**"
      ],
      "metadata": {
        "id": "SeJDgsPWSWAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El uso de memoria si disminuye considerablemente pasando de 2k MiB a solo 43 MiB. Sin embargo no parece haber gran diferencia en el tiempo de ejecuci√≥n.\n",
        "\n",
        "Pienso que una razon de esto puede ser la lectura del archivo, realizare unas modificaciones para probar una forma mas rapida de leerlo."
      ],
      "metadata": {
        "id": "iwuQfyG3PeSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intentare cargar los datos con una libreria para parsear el json mas rapidament"
      ],
      "metadata": {
        "id": "OQApcpInWrQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import orjson\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
        "    data = []\n",
        "    with open(file_path, 'rb') as f:\n",
        "        for line in f:\n",
        "            tweet = orjson.loads(line)\n",
        "            data.append({\n",
        "                'date': tweet['date'],\n",
        "                'username': tweet['user']['username']\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
        "\n",
        "    date_counts = df['date'].value_counts()\n",
        "    top_dates = date_counts.nlargest(10).index\n",
        "\n",
        "    df_top_dates = df[df['date'].isin(top_dates)]\n",
        "    user_date_counts = df_top_dates.groupby(['date', 'username']).size().reset_index(name='counts')\n",
        "\n",
        "    idx = user_date_counts.groupby('date')['counts'].idxmax()\n",
        "    top_users = user_date_counts.loc[idx]\n",
        "\n",
        "    result = list(zip(top_users['date'], top_users['username']))\n",
        "\n",
        "    return result\n",
        "\n",
        "q1_time(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4G0W9kHJ8pf",
        "outputId": "94715cb1-98ec-4646-edc4-aae1939025f7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
              " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
              " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
              " (datetime.date(2021, 2, 15), 'jot__b'),\n",
              " (datetime.date(2021, 2, 16), 'jot__b'),\n",
              " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
              " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
              " (datetime.date(2021, 2, 19), 'Preetm91'),\n",
              " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
              " (datetime.date(2021, 2, 23), 'Surrypuria')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "import pstats\n",
        "import io\n",
        "\n",
        "pr = cProfile.Profile()\n",
        "\n",
        "pr.enable()\n",
        "result = q1_time(file_path)\n",
        "pr.disable()\n",
        "\n",
        "s = io.StringIO()\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats('cumulative' )\n",
        "ps.print_stats(5)\n",
        "print(s.getvalue())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnszgdauVrHC",
        "outputId": "c36ebe98-f5cf-4da0-cc63-36465ed83617"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         477212 function calls (477079 primitive calls) in 3.849 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "   List reduced from 737 to 5 due to restriction <5>\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        2    0.000    0.000    3.849    1.924 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3512(run_code)\n",
            "        2    0.000    0.000    3.849    1.924 {built-in method builtins.exec}\n",
            "        1    0.029    0.029    3.849    3.849 <ipython-input-31-ca349d025676>:1(<cell line: 8>)\n",
            "        1    0.992    0.992    3.820    3.820 <ipython-input-30-09eb1a8e88ef>:5(q1_time)\n",
            "   117407    2.382    0.000    2.382    0.000 {orjson.loads}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler\n",
        "!python /content/q1_time_mp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oegPgBJnWApf",
        "outputId": "e3a78de2-bd8d-4d96-fe31-caa7a3fa4654"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Filename: /content/q1_time_mp.py\n",
            "\n",
            "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
            "=============================================================\n",
            "     7    117.0 MiB    117.0 MiB           1   @profile\n",
            "     8                                         def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
            "     9    117.0 MiB      0.0 MiB           1       data = []\n",
            "    10    161.9 MiB      0.0 MiB           2       with open(file_path, 'rb') as f:\n",
            "    11    161.9 MiB      1.5 MiB      117408           for line in f:\n",
            "    12    161.9 MiB     34.0 MiB      117407               tweet = orjson.loads(line)\n",
            "    13    161.9 MiB      9.3 MiB      234814               data.append({\n",
            "    14    161.9 MiB      0.0 MiB      117407                   'date': tweet['date'],\n",
            "    15    161.9 MiB      0.0 MiB      117407                   'username': tweet['user']['username']\n",
            "    16                                                     })\n",
            "    17                                         \n",
            "    18    164.3 MiB      2.4 MiB           1       df = pd.DataFrame(data)\n",
            "    19    171.3 MiB      7.0 MiB           1       df['date'] = pd.to_datetime(df['date']).dt.date\n",
            "    20                                         \n",
            "    21    171.3 MiB      0.0 MiB           1       date_counts = df['date'].value_counts()\n",
            "    22    172.3 MiB      1.0 MiB           1       top_dates = date_counts.nlargest(10).index\n",
            "    23                                         \n",
            "    24    174.4 MiB      2.0 MiB           1       df_top_dates = df[df['date'].isin(top_dates)]\n",
            "    25    177.2 MiB      2.8 MiB           1       user_date_counts = df_top_dates.groupby(['date', 'username']).size().reset_index(name='counts')\n",
            "    26                                         \n",
            "    27    177.2 MiB      0.0 MiB           1       idx = user_date_counts.groupby('date')['counts'].idxmax()\n",
            "    28    177.2 MiB      0.0 MiB           1       top_users = user_date_counts.loc[idx]\n",
            "    29                                         \n",
            "    30    177.2 MiB      0.0 MiB           1       result = list(zip(top_users['date'], top_users['username']))\n",
            "    31                                         \n",
            "    32    177.2 MiB      0.0 MiB           1       return result\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Observaciones**"
      ],
      "metadata": {
        "id": "6FPHP5jUXHK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsear los datos con otra libreria, utilizar solo las columnas necesarias para armar el dataframe y utilizar las funciones nativas de pandas para calcular las agregaciones ayudo a reducir el tiempo de ejecucion a solo 3 seg,  incluso redujo el uso de memoria."
      ],
      "metadata": {
        "id": "kMaxedEYXKwc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1BR6OmTpWM9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Los top 10 emojis m√°s usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
        "```python\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "```\n",
        "```python\n",
        "Returns:\n",
        "[(\"‚úàÔ∏è\", 6856), (\"‚ù§Ô∏è\", 5876), ...]\n",
        "```"
      ],
      "metadata": {
        "id": "Dlgbh7ZidWbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import orjson\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    data = []\n",
        "    with open(file_path, 'rb') as f:\n",
        "        for line in f:\n",
        "            tweet = orjson.loads(line)\n",
        "            data.append({\n",
        "                'content': tweet['content'],\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    contents = df['content']\n",
        "\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
        "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE\n",
        "    )\n",
        "\n",
        "    def extract_emojis(text):\n",
        "        return emoji_pattern.findall(text)\n",
        "\n",
        "    df['emojis'] = contents.apply(extract_emojis)\n",
        "\n",
        "    emojis_series = df['emojis'].explode()\n",
        "\n",
        "    emojis_series = emojis_series.dropna()\n",
        "\n",
        "    emoji_counts = emojis_series.value_counts()\n",
        "\n",
        "    top_emojis = emoji_counts.head(10)\n",
        "\n",
        "    result = list(top_emojis.items())\n",
        "\n",
        "    return result\n",
        "\n",
        "q2_time(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRcWTJ-ddcCM",
        "outputId": "58f947f9-125a-42e2-8bbe-3f1826188763"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('üôè', 1916),\n",
              " ('‚ù§Ô∏è', 952),\n",
              " ('üòÇ', 627),\n",
              " ('üåæ', 529),\n",
              " ('üíö', 493),\n",
              " ('üëç', 459),\n",
              " ('üëâ', 450),\n",
              " ('‚úä', 437),\n",
              " ('üáÆüá≥', 399),\n",
              " ('üëá', 387)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "import pstats\n",
        "import io\n",
        "\n",
        "pr = cProfile.Profile()\n",
        "\n",
        "pr.enable()\n",
        "result = q2_time(file_path)\n",
        "pr.disable()\n",
        "\n",
        "s = io.StringIO()\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats('cumulative' )\n",
        "ps.print_stats(5)\n",
        "print(s.getvalue())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXJo8cnKfJ_x",
        "outputId": "487e9e70-1abc-48f2-c950-2a3e5a17e460"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         706253 function calls (706219 primitive calls) in 4.733 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "   List reduced from 341 to 5 due to restriction <5>\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        2    0.000    0.000    4.733    2.367 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3512(run_code)\n",
            "        2    0.000    0.000    4.733    2.367 {built-in method builtins.exec}\n",
            "        1    0.050    0.050    4.733    4.733 <ipython-input-39-6074579cebf1>:1(<cell line: 8>)\n",
            "        1    0.882    0.882    4.683    4.683 <ipython-input-38-5c5a12b0916e>:6(q2_time)\n",
            "   117407    1.978    0.000    1.978    0.000 {orjson.loads}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler\n",
        "!python /content/q2_time_mp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSbrmoELfOEP",
        "outputId": "a4d12c4d-893d-4e3c-f0ec-6f1db38b5c88"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Filename: /content/q2_time_mp.py\n",
            "\n",
            "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
            "=============================================================\n",
            "     7    117.0 MiB    117.0 MiB           1   @profile\n",
            "     8                                         def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
            "     9    117.0 MiB      0.0 MiB           1       data = []\n",
            "    10    184.1 MiB      0.0 MiB           2       with open(file_path, 'rb') as f:\n",
            "    11    184.1 MiB      6.2 MiB      117408           for line in f:\n",
            "    12    184.1 MiB     44.9 MiB      117407               tweet = orjson.loads(line)\n",
            "    13    184.1 MiB     16.0 MiB      234814               data.append({\n",
            "    14    184.1 MiB      0.0 MiB      117407                   'content': tweet['content'],\n",
            "    15                                                     })\n",
            "    16                                         \n",
            "    17    186.1 MiB      2.1 MiB           1       df = pd.DataFrame(data)\n",
            "    18                                         \n",
            "    19    186.1 MiB      0.0 MiB           1       contents = df['content']\n",
            "    20                                         \n",
            "    21    186.1 MiB      0.0 MiB           2       emoji_pattern = re.compile(\n",
            "    22    186.1 MiB      0.0 MiB           1           \"[\"\n",
            "    23                                                 \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
            "    24                                                 \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
            "    25                                                 \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
            "    26                                                 \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
            "    27                                                 \"\\U00002702-\\U000027B0\"  # Dingbats\n",
            "    28                                                 \"\\U000024C2-\\U0001F251\"\n",
            "    29                                                 \"]+\",\n",
            "    30    186.1 MiB      0.0 MiB           1           flags=re.UNICODE\n",
            "    31                                             )\n",
            "    32                                         \n",
            "    33    196.1 MiB      6.7 MiB      117408       def extract_emojis(text):\n",
            "    34    196.1 MiB      3.2 MiB      117407           return emoji_pattern.findall(text)\n",
            "    35                                         \n",
            "    36    196.9 MiB      0.9 MiB           1       df['emojis'] = contents.apply(extract_emojis)\n",
            "    37                                         \n",
            "    38    203.2 MiB      6.2 MiB           1       emojis_series = df['emojis'].explode()\n",
            "    39                                         \n",
            "    40    201.3 MiB     -1.9 MiB           1       emojis_series = emojis_series.dropna()\n",
            "    41                                         \n",
            "    42    201.3 MiB      0.0 MiB           1       emoji_counts = emojis_series.value_counts()\n",
            "    43                                         \n",
            "    44    201.3 MiB      0.0 MiB           1       top_emojis = emoji_counts.head(10)\n",
            "    45                                         \n",
            "    46    201.3 MiB      0.0 MiB           1       result = list(top_emojis.items())\n",
            "    47                                         \n",
            "    48    201.3 MiB      0.0 MiB           1       return result\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
        "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE\n",
        "    )\n",
        "\n",
        "    emoji_counts = defaultdict(int)\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                content = tweet.get('content', '')\n",
        "                emojis = emoji_pattern.findall(content)\n",
        "                for emoji in emojis:\n",
        "                    emoji_counts[emoji] += 1\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    top_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    return top_emojis\n",
        "\n",
        "q2_memory(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnhL8OdZhXTp",
        "outputId": "0971bc53-1146-4795-f164-c03ced9e069e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('üôè', 1916),\n",
              " ('‚ù§Ô∏è', 952),\n",
              " ('üòÇ', 627),\n",
              " ('üåæ', 529),\n",
              " ('üíö', 493),\n",
              " ('üëç', 459),\n",
              " ('üëâ', 450),\n",
              " ('‚úä', 437),\n",
              " ('üáÆüá≥', 399),\n",
              " ('üëá', 387)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "import pstats\n",
        "import io\n",
        "\n",
        "pr = cProfile.Profile()\n",
        "\n",
        "pr.enable()\n",
        "result = q2_memory(file_path)\n",
        "pr.disable()\n",
        "\n",
        "s = io.StringIO()\n",
        "ps = pstats.Stats(pr, stream=s).sort_stats('cumulative' )\n",
        "ps.print_stats(5)\n",
        "print(s.getvalue())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjakEcOQj64f",
        "outputId": "073128d8-4fe5-49ae-ccc8-b9cb16bf2700"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         1511575 function calls in 8.862 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "   List reduced from 50 to 5 due to restriction <5>\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        2    0.000    0.000    8.862    4.431 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3512(run_code)\n",
            "        2    0.000    0.000    8.862    4.431 {built-in method builtins.exec}\n",
            "        1    0.000    0.000    8.862    8.862 <ipython-input-44-c1c9d4bd62b3>:1(<cell line: 8>)\n",
            "        1    1.842    1.842    8.861    8.861 <ipython-input-43-badbe05d4749>:6(q2_memory)\n",
            "   117407    0.229    0.000    5.878    0.000 /usr/lib/python3.10/json/__init__.py:299(loads)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler\n",
        "!python /content/q2_memory_mp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCoD_2fyj6ph",
        "outputId": "4e8dd53d-0469-4b3f-c134-2823a357d89a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Filename: /content/q2_memory_mp.py\n",
            "\n",
            "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
            "=============================================================\n",
            "     7     38.2 MiB     38.2 MiB           1   @profile\n",
            "     8                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
            "     9     38.2 MiB      0.0 MiB           2       emoji_pattern = re.compile(\n",
            "    10     38.2 MiB      0.0 MiB           1           \"[\"\n",
            "    11                                                 \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
            "    12                                                 \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
            "    13                                                 \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
            "    14                                                 \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
            "    15                                                 \"\\U00002702-\\U000027B0\"  # Dingbats\n",
            "    16                                                 \"\\U000024C2-\\U0001F251\"\n",
            "    17                                                 \"]+\",\n",
            "    18     38.2 MiB      0.0 MiB           1           flags=re.UNICODE\n",
            "    19                                             )\n",
            "    20                                         \n",
            "    21     38.2 MiB      0.0 MiB           1       emoji_counts = defaultdict(int)\n",
            "    22                                         \n",
            "    23     39.0 MiB      0.0 MiB           2       with open(file_path, 'r', encoding='utf-8') as f:\n",
            "    24     39.0 MiB      0.5 MiB      117408           for line in f:\n",
            "    25     39.0 MiB      0.0 MiB      117407               try:\n",
            "    26     39.0 MiB      0.3 MiB      117407                   tweet = json.loads(line)\n",
            "    27     39.0 MiB      0.0 MiB      117407                   content = tweet.get('content', '')\n",
            "    28     39.0 MiB      0.0 MiB      117407                   emojis = emoji_pattern.findall(content)\n",
            "    29     39.0 MiB      0.0 MiB      138865                   for emoji in emojis:\n",
            "    30     39.0 MiB      0.0 MiB       21458                       emoji_counts[emoji] += 1\n",
            "    31                                                     except json.JSONDecodeError:\n",
            "    32                                                         continue\n",
            "    33                                         \n",
            "    34     39.0 MiB      0.0 MiB        6153       top_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
            "    35                                         \n",
            "    36     39.0 MiB      0.0 MiB           1       return top_emojis\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Observaciones**"
      ],
      "metadata": {
        "id": "YYuUHpG7fx_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliz√≥ la misma libreria, ya que la lectura del archivo es mas eficiente.\n",
        "Probablemente se podia mejorar la funcion utilizando una libreria enfocada a detectar emojis en lugar de utilizar los unicode."
      ],
      "metadata": {
        "id": "sWUrCWUWf1U5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O985bjASf02r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}